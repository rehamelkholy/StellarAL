{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils as u\n",
    "import pickle as pkl\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53176, 9) (53176,)\n",
      "(5909, 9) (5909,)\n"
     ]
    }
   ],
   "source": [
    "file_name = 'sec3_1_data_output_teff.pkl'\n",
    "n_features = 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = u.load_pkl_data(file_name)\n",
    "X_train, X_test = X_train[:,:n_features], X_test[:,:n_features]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare `margin` and `random` sampling sensitivity for `n` instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random (10% of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "n_runs = 20\n",
    "n_rand = int(X_train.shape[0]*0.1)\n",
    "scores_rand = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    X_rand, y_rand, _, _ = u.get_initial_sample_pool(X_train, y_train, n_rand)\n",
    "    scores_rand.append(u.get_baseline_model(X_rand, y_rand, X_test, y_test).sen.at[1])\n",
    "    \n",
    "scores_rand = np.array(scores_rand)\n",
    "rand_mean = np.mean(scores_rand)\n",
    "rand_std = np.std(scores_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified (10% of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_runs = 20\n",
    "n_strat = int(X_train.shape[0]*0.1)\n",
    "scores_strat = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    _, X_strat, _, y_strat = train_test_split(X_train, y_train, test_size=n_strat/X_train.shape[0], stratify=y_train)\n",
    "    scores_strat.append(u.get_baseline_model(X_strat, y_strat, X_test, y_test).sen.at[1])\n",
    "    \n",
    "scores_strat = np.array(scores_strat)\n",
    "strat_mean = np.mean(scores_strat)\n",
    "strat_std = np.std(scores_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin (5% of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWARNING: the following cell might take hours to finish running!\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "WARNING: the following cell might take hours to finish running!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial batch size: 10\n",
      "Run 5 of 5\n",
      "Query 2648 of 2648\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "n_initial = 10\n",
    "n_instances = int(X_train.shape[0]*0.05 - n_initial)\n",
    "n_runs = 5\n",
    "\n",
    "scores_al = []\n",
    "\n",
    "for run in range(n_runs):\n",
    "    X_initial, y_initial, X_pool, y_pool = u.get_initial_sample_pool(X_train, y_train, n_initial)\n",
    "    \n",
    "    clear_output()\n",
    "    print('Initial batch size:', n_initial)\n",
    "    print('Run', run+1, 'of', n_runs)\n",
    "    scores_al.append(u.test_sampling_method(X_initial, y_initial, X_pool, y_pool, 'rf', 'margin', X_test, y_test, 7, n_instances)[2])\n",
    "\n",
    "scores_al = np.array(scores_al)\n",
    "sen_al_mean = np.mean(scores_al, axis=0)\n",
    "sen_al_std = np.std(scores_al, axis=0)\n",
    "    \n",
    "print('\\nDone!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data to results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open results file\n",
    "file_name = 'results.pkl'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new results to file data\n",
    "data['rand_10_percent'] = rand_mean, rand_std\n",
    "data['strat_10_percent'] = strat_mean, strat_std\n",
    "data['al_marg_5_percent'] = sen_al_mean, sen_al_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in file 'results.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# save updated data to results file\n",
    "with open(file_name, 'wb') as f:\n",
    "    pkl.dump(data, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Results saved in file '\" + file_name + \"'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
